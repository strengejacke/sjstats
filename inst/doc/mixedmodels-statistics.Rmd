---
title: "Statistics for Mixed Effects Models"
author: "Daniel Lüdecke"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Statistics for Mixed Effects Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r set-options, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", dev = "png", fig.width = 7, fig.height = 3.5, message = FALSE, warning = FALSE)
options(width = 800)
```

# Statistics and Measures for Mixed Effects Models

This vignettes demontrates those functions of the *sjstats*-package that deal especially with mixed effects models. *sjstats* provides following functions:

* `deff()` and `smpsize_lmm()`
* `converge_ok()` and `is_singular()`
* `p_value()`
* `scale_weights()`
* `get_re_var()` and `re_var()`
* `icc()`
* `r2()`


Befor we start, we fit a simple linear mixed model:

```{r}
library(sjstats)
library(lme4)
# load sample data
data(sleepstudy)

# fit linear mixed model
m <- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)

sleepstudy$mygrp <- sample(1:45, size = 180, replace = TRUE)
m2 <- lmer(Reaction ~ Days + (1 | mygrp) + (1 | Subject), sleepstudy)
```

## Sample Size Calculation for Mixed Models

The first two functions, `deff()` and `smpsize_lmm()`, can be used to approximately calculate the sample size in the context of power calculation. Calculating the sample size for simple linear models is pretty straightforward, however, for (linear) mixed models, statistical power is affected through the change of the variance of test statistics. This is what Hsieh et al. (2003) call a _design effect_ (or variance inflation factor, VIF). Once this design effect is calculated, the sample size calculated for a standard design can be adjusted accordingly.

### Design Effect for Two-Level Mixed Models

`deff()` computes this design effect for linear mixed models with two-level design. It requires the approximated average number of observations per grouping cluster (i.e. level-2 unit) and the assumed intraclass correlation coefficient (ICC) for the multilevel-model. Typically, the minimum assumed value for the ICC is _0.05_.

```{r}
# Design effect for two-level model with 30 observations per
# cluster group (level-2 unit) and an assumed intraclass
# correlation coefficient of 0.05.
deff(n = 30)

# Design effect for two-level model with 24 observation per cluster
# group and an assumed intraclass correlation coefficient of 0.2.
deff(n = 24, icc = 0.2)
```

### Calculating the Sample Size for Linear Mixed Models

`smpsize_lmm()` combines the functions for power calculation from the **pwr**-package and design effect `deff()`. It computes an approximated sample size for linear mixed models (two-level-designs), based on power-calculation for standard design and adjusted for design effect for 2-level-designs.

```{r}
# Sample size for multilevel model with 30 cluster groups and a small to
# medium effect size (Cohen's d) of 0.3. 27 subjects per cluster and
# hence a total sample size of about 802 observations is needed.
smpsize_lmm(eff.size = .3, k = 30)

# Sample size for multilevel model with 20 cluster groups and a medium
# to large effect size for linear models of 0.2. Five subjects per cluster and
# hence a total sample size of about 107 observations is needed.
smpsize_lmm(eff.size = .2, df.n = 5, k = 20, power = .9)
```

There are more ways to perform power calculations for multilevel models, however, most of these require very detailed knowledge about the sample characteristics and performing simulation studys. `smpsize_lmm()` is a more pragmatic alternative to these approaches.

## Trouble Shooting

Sometimes, when fitting mixed models, covergence warnings or warnings about singularity may come up (see details on these issues [in this FAQ](http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#troubleshooting)). These warnings may arise due to the strict tresholds and / or may be safely ignored. `converge_ok()` and `is_singular()` may help to check whether such a warning is problematic or not.

`converge_ok()` provides an alternative convergence test for merMod-objects (with a less strict treshold, as suggested by one of the _lme4_-package authors), while `is_singular()` can be used in case of post-fitting convergence warnings, such as warnings about negative eigenvalues of the Hessian. In both cases, if the function returns `TRUE`, these warnings can most likely be ignored.

```{r}
converge_ok(m)

is_singular(m)
```

## Rescale model weights for complex samples

Most functions to fit multilevel and mixed effects models only allow to specify frequency weights, but not design (i.e. _sampling_ or _probability_) weights, which should be used when analyzing complex samples and survey data.

`scale_weights()` implements an algorithm proposed by Aaparouhov (2006) and Carle (2009) to rescale design weights in survey data to account for the grouping structure of multilevel models, which then can be used for multilevel modelling. 

To calculate a weight-vector that can be used in multilevel models, `scale_weights()` needs the data frame with survey data as `x`-argument. This data frame should contain 1) a _cluster ID_ (argument `cluster.id`), which represents the _strata_ of the survey data (the level-2-cluster variable) and 2) the probability weights (argument `pweight`), which represents the design or sampling weights of the survey data (level-1-weight).

`scale_weights()` then returns the original data frame, including two new variables: `svywght_a`, where the sample weights `pweight` are adjusted by a factor that represents the proportion of cluster size divided by the sum of sampling weights within each cluster. The adjustment factor for `svywght_b` is the sum of sample weights within each cluster devided by the sum of squared sample weights within each cluster (see Carle (2009), Appendix B, for details).

```{r}
data(nhanes_sample)
scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)
```

## P-Values

For linear mixed models, the `summary()` in **lme4** does not report p-values. Other objects from regression functions are not consistent in their output structure when reporting p-values. `p_value()` aims at returning a standardized ("tidy") output for any regression model. The return value is always a data frame with three columns: _term_, _p.value_ and _std.error_, which represent the name, p-value and standard error for each term.

For linear mixed models, the approximation of p-values are more precise when `p.kr = TRUE`, based on conditional F-tests with Kenward-Roger approximation for the degrees of freedom (calling `pbkrtest::get_Lb_ddf()`).

```{r}
# Using the t-statistics for calculating the p-value
p_value(m2)

# p-values based on conditional F-tests with 
# Kenward-Roger approximation for the degrees of freedom
p_value(m2, p.kr = TRUE)
```

To see more details on the degrees of freedom when using Kenward-Roger approximation, use the `summary()`-method:

```{r}
pv <- p_value(m2, p.kr = TRUE)
summary(pv)
```

## Random Effect Variances

In mixed effects models, several random effect variances (depending on the model specification) are calculated:

* `sigma_2`: Within-group (residual) variance
* `tau.00`: Between-group-variance (variation between individual intercepts and average intercept)
* `tau.11`: Random-slope-variance (variation between individual slopes and average slope)
* `tau.01`: Random-Intercept-Slope-covariance
* `rho.01`: Random-Intercept-Slope-correlation

You can access on of these values with `get_re_var()`, or all of them with `re_var()`:

```{r}
# get residual variance
get_re_var(m, "sigma_2")

# get all random effect variances
re_var(m)
```

## R-squared

Nakagawa et al. (2017) proposed a method to compute marginal and conditional r-squared values, which is implemented in the `r2()`-function. For mixed models, the marginal r-squared considers only the variance of the fixed effects, while the conditional r-squared takes both the fixed and random effects into account. `r2()` can be used with models fitted with the functions of the **lme4** and **glmmTMB** packages. 

```{r}
r2(m)
```

## Intraclass-Correlation Coefficient

The components of the random effect variances are of interest when calculating the intraclass-correlation coefficient, ICC. The ICC is calculated by dividing the between-group-variance (random intercept variance) by the total variance (i.e. sum of between-group-variance and within-group (residual) variance). The ICC can be interpreted as "the proportion of the variance explained by the grouping structure in the population" (Hox 2002: 15). 

Usually, the ICC is calculated for the null model ("unconditional model"). However, according to Raudenbush and Bryk (2002) or Rabe-Hesketh and Skrondal (2012) it is also feasible to compute the ICC for full models with covariates ("conditional models") and compare how much a level-2 variable explains the portion of variation in the grouping structure (random intercept). 

The ICC for mixed models can be computed with `icc()`. *Caution:* For random-slope-intercept models, the ICC would differ at each unit of the predictors. Hence, the ICC for these kind of models cannot be understood simply as proportion of variance (see Goldstein et al. 2010). For convenience reasons, as the `icc()` function is also used to extract the different random effects variances (see `re_var()` above), the ICC for random-slope-intercept-models is reported nonetheless, but it is usually no meaningful summary of the proportion of variances. 

By default, for three-level-models, depending on the nested structure of the model, or for cross-classified models, `icc()` only reports the proportion of variance explained for each grouping level. Use `adjusted = TRUE` to calculate the adjusted and conditional ICC. 

```{r message = TRUE}
icc(m)

icc(m2)
```

If `adjusted = TRUE`, an adjusted and conditional ICC are calculated, which take all sources of uncertainty (of all random effects) into account to report an "adjusted" ICC, as well as the conditional ICC. The latter also takes the fixed effects variances into account (see Nakagawa et al. 2017). If random effects are not nested and not cross-classified, the adjusted (`adjusted = TRUE`) and unadjusted (`adjusted = FALSE`) ICC are identical. 

```{r message = TRUE}
icc(m, adjusted = TRUE)

icc(m2, adjusted = TRUE)
```

# References

Aaparouhov T. 2006. _General Multi-Level Modeling with Sampling Weights._ Communications in Statistics—Theory and Methods (35): 439–460

Carle AC. 2009. _Fitting multilevel models in complex survey data with design weights: Recommendations._ BMC Medical Research Methodology 9(49): 1-13 

Goldstein H, Browne W, Rasbash J. 2010. Partitioning Variation in Multilevel Models. Understanding Statistics, 1:4, 223-231, doi: [10.1207/S15328031US0104_02](http://doi.org/10.1207/S15328031US0104_02)

Hox J. 2002. _Multilevel analysis: techniques and applications._ Mahwah, NJ: Erlbaum

Hsieh FY, Lavori PW, Cohen HJ, Feussner JR. 2003. _An Overview of Variance Inflation Factors for Sample-Size Calculation._ Evaluation & the Health Professions 26: 239–257. doi: [10.1177/0163278703255230](http://doi.org/10.1177/0163278703255230)

Nakagawa S, Johnson P, Schielzeth H. 2017. The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisted and expanded. J. R. Soc. Interface 14. doi: [10.1098/rsif.2017.0213](http://doi.org/10.1098/rsif.2017.0213)

Rabe-Hesketh S, Skrondal A. 2012. _Multilevel and longitudinal modeling using Stata._ 3rd ed. College Station, Tex: Stata Press Publication

Raudenbush SW, Bryk AS. 2002. _Hierarchical linear models: applications and data analysis methods._ 2nd ed. Thousand Oaks: Sage Publications
