---
title: "Statistics for Bayesian Models"
author: "Daniel Lüdecke"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
params:
    EVAL: !r identical(Sys.getenv("NOT_CRAN"), "true")
---

<!--
vignette: >
  %\VignetteIndexEntry{Statistics for Bayesian Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
-->

```{r, SETTINGS-knitr, echo = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, 
  comment = "#>", 
  dev = "png", 
  fig.width = 7, 
  fig.height = 5, 
  message = FALSE, 
  warning = FALSE, 
  eval = if (isTRUE(exists("params"))) params$EVAL else FALSE
)

options(width = 800, tibble.width = Inf)

if (!requireNamespace("mediation", quietly = TRUE)) {
  warning("Package 'mediation' required for this vignette.", call. = FALSE)
}
```

This vignettes demontrates those functions of the *sjstats*-package that deal especially with Bayesian models. *sjstats* provides following functions:

* `hdi()`
* `rope()`
* `mcse()`
* `n_eff()`
* `tidy_stan()`
* `equi_test()`
* `mediation()`
* `icc()`
* `r2()`

Befor we start, we fit some models, including a mediation-object from the _mediation_-package, which we use for comparison with _brms_. The functions work with `brmsfit`, `stanreg` and `stanfit`-objects.

```{r}
library(sjstats)
library(sjmisc)
library(mediation)
library(brms)

# load sample data
data(jobs)
data(efc)
efc <- to_factor(efc, e42dep, c172code, c161sex, e15relat)
zinb <- read.csv("http://stats.idre.ucla.edu/stat/data/fish.csv")

# linear models, for mediation analysis
b1 <- lm(job_seek ~ treat + econ_hard + sex + age, data = jobs)
b2 <- lm(depress2 ~ treat + job_seek + econ_hard + sex + age, data = jobs)

# mediation analysis, for comparison with brms
m1 <- mediate(b1, b2, sims = 1000, treat = "treat", mediator = "job_seek")

# fit Bayesian models
f1 <- bf(job_seek ~ treat + econ_hard + sex + age)
f2 <- bf(depress2 ~ treat + job_seek + econ_hard + sex + age)

m2 <- brm(f1 + f2 + set_rescor(FALSE), data = jobs, cores = 4)

m3 <- brm(
  bf(count ~ child + camper + (1 | persons), 
     zi ~ child + camper + (1 | persons)),
  data = zinb,
  family = zero_inflated_poisson(),
  cores = 4
)

m4 <- brm(
  mpg ~ wt + hp + (1 | cyl) + (1 + wt | gear), 
  data = mtcars, 
  cores = 4
)

m5 <- brm(
  neg_c_7 ~ e42dep + c12hour + c172code + (1 | e15relat),
  data = efc,
  cores = 4
)
```

## Highest Density Interval

`hdi()` computes the highest density interval for posterior samples. Unlike equal-tailed intervals that exclude 2.5% from each tail of the distribution, the HDI is _not_ equal-tailed and therefor always includes the mode(s) of posterior distributions.

By default, `hdi()` prints the 90% intervals, however, the `prob`-argument can be used to calculate different or even multiple intervals.

```{r}
hdi(m2)

hdi(m2, prob = c(.5, .89))
```

For multilevel models, the `type`-argument defines whether the HDI of fixed, random or all effects are shown.

```{r}
hdi(m5, type = "random")
```

The computation for the HDI is based on the code from _Kruschke 2015, pp. 727f_. For default sampling in Stan (4000 samples), the 90% intervals for HDI are more stable than, for instance, 95% intervals. An effective sample size of at least 10.000 is recommended if 95% intervals should be computed (see _Kruschke 2015, p. 183ff_).

## Region of Practical Equivalence (ROPE)

Unlike a frequentist approach, Bayesian inference is not based on stastical significance, where effects need to be different from "zero". Rather, the magnitude of a model's parameter value and its uncertainty should not be ignored, and hence, an effect is not present when it simply differs from zero, but if it's outside a specific range that can be considered as "practically no effect". This range is called the _region of practical equivalence_ (ROPE).

`rope()` requires the `rope`-argument, which defined this region, and then gives a summary about the parameters and their proportion that lies inside and outside this ROPE.

```{r}
rope(m5, rope = c(-1, 1))
```

`rope()` does not suggest limits for the region of practical equivalence and does not tell you how big is practically equivalent to the null value. However, there are suggestions how to choose reasonable limits (see _Kruschke 2018_), which are implemented in the `equi_test()` functions.

## Test for Practical Equivalence

`equi_test()` combines the two functions `hdi()` and `rope()` and performs a "HDI+ROPE decision rule" (Test for Practical Equivalence) (_Kruschke 2018_) to check whether parameter values should be accepted or rejected against the background of a formulated null hypothesis.

`equi_test()` computes the 95%-HDI and checks if a model predictor's HDI lies completely outside, completely inside or partially inside the ROPE. If the HDI is completely outside the ROPE, the "null hypothesis" for this parameter is "rejected". If the ROPE completely covers the HDI, i.e. all most credible values of a parameter are inside the region of practical equivalence, the null hypothesis is accepted. Else, it's undecided whether to accept or reject the null hypothesis. In short, desirable results are low proportions inside the ROPE (the closer to zero the better) and the H0 should be rejected. 

If neither the `rope` nor `eff_size` argument are specified, the effect size will be set to 0.1 (half of a small effect according to Cohen) and the ROPE is then `0 +/- .1 * sd(y)` for linear models. This is the suggested way to specify the ROPE limits according to _Kruschke_ (2018).

```{r, message=TRUE}
equi_test(m5)
```

For models with binary outcome, there is no concrete way to derive the effect size that defines the ROPE limits. Two examples from Kruschke suggest that a negligible change is about .05 on the logit-scale. In these cases, it is recommended to specify the `rope` argument, however, if not specified, the ROPE limits are calculated in this way: `0 +/- .1 * sd(intercept) / 4`. For all other models, `0 +/- .1 * sd(intercept)` is used to determine the ROPE limits. These formulas are based on experience that worked well in real-life situations, but are most likely not generally the best approach.

Beside a numerical output, the results can also be plotted, using the `plot`-argument. In this case, the 95% distributions of the posterior samles are shown, the ROPE is a light-blue shaded region in the plot, and the distributions are colored depending on whether the parameter values are accepted, rejected or undecided.

```{r}
equi_test(m5, plot = TRUE)
```

## Tidy Summary of Bayesian Models

`tidy_stan()` is no substitute, but rather a convenient alternative to `summary()`. The major differences are: `tidy_stan()`...

  * focusses on the parameter values (estimates) and gives no information on samples, data, or formula
  * calculates the HDI rather than equi-tailed intervals
  * separates different model parts, e.g. random from fixed effects, or conditional from zero-inflated models
  * and prints everything nicely

```{r}
tidy_stan(m3)
```

Additional statistics in the output are:

  * standard errors (which are actually median absolute deviations)
  * ratio of effective numbers of samples, *neff_ratio*, (i.e. effective number of samples divided by total number of samples); this ratio ranges from 0 to 1, and should be close to 1; the closer this ratio comes to zero means that the chains may be inefficient, but possibly still okay
  * Rhat statistics; when Rhat is above 1, it usually indicates that the chain has not yet converged, indicating that the drawn samples might not be trustworthy; drawing more iteration may solve this issue
  * Monte Carlo Standard Error (_mcse_);

By default, the "estimate" is the median of the posterior distribution, but this can be changed with the `typical`-argument.

```{r}
tidy_stan(m3, typical = "mean")
```

To also show random effects of multilevel models, use the `type`-argument.

```{r}
# printing fixed and random effects of multilevel model
tidy_stan(m3, type = "all")
```

By default, 89%-HDI are computed (a convention following _McElreath 2015_), but other or even multiple HDI can be computed using the `prob` argument.

```{r}
# two different HDI for multivariate response model
tidy_stan(m2, prob = c(.5, .95))
```

## Summary of Mediation Analysis

`mediation()` is another summary function, especially for mediation analysis, i.e. for multivariate response models with casual mediation effects.

Let us recall the models:

```{r eval=FALSE}
f1 <- bf(job_seek ~ treat + econ_hard + sex + age)
f2 <- bf(depress2 ~ treat + job_seek + econ_hard + sex + age)

m2 <- brm(f1 + f2 + set_rescor(FALSE), data = jobs, cores = 4)
```

Here, _treat_ is the treatment effect, *job_seek* is the moderator effect, _f1_ describes the moderator model and _f2_ describes the outcome model.

`mediation()` returns a data frame with information on the _direct effect_ (mean value of posterior samples from treatment of the outcome model), _mediator effect_ (mean value of posterior samples from mediator of the outcome model), _indirect effect_ (mean value of the multiplication of the posterior samples from mediator of the outcome model and the posterior samples from treatment of the mediation model) and the _total effect_ (mean value of sums of posterior samples used for the direct and indirect effect). The _proportion mediated_ is the indirect effect divided by the total effect. 

The simplest call just needs the model-object.

```{r, message=TRUE}
mediation(m2)
```

Typically, `mediation()` finds the treatment and mediator variables automatically. If this does not work, use the `treatment` and `mediator` arguments to specify the related variable names. For all values, the 90% HDIs are calculated by default. Use `prob` to calculate a different interval. 

Here is a comparison with the _mediation_ package. Note that the `summary()`-output of the _mediation_ package shows the indirect effect first, followed by the direct effect.

```{r}
summary(m1)

mediation(m2, prob = .95)
```

There is a `print()`-method, which allows to print more digits.

```{r, message=TRUE}
mediation(m2, prob = .95) %>% print(digits = 4)
```

As you can see, the results are similar to what the _mediation_ package produces for non-Bayesian models.

## ICC for multilevel models

Similar to [frequentist multilevel models](mixedmodels-statistics.html), `icc()` computes the intraclass correlation coefficient for Bayesian multilevel models.

```{r}
icc(m5)
```

One advantage of the _brms_ package is that you can compute the ICC for each sample of the posterior distribution, which allows you to easily calculate uncertainty intervals.

```{r, message=TRUE}
icc(m4, posterior = TRUE)

icc(m5, posterior = TRUE)
```

There's also a `print()`-method which allows you to specify the HDI-interval and digits:

```{r}
icc(m5, posterior = TRUE) %>% print(prob = .95, digits = 3)
```

## Bayes r-squared and LOO-adjusted r-squared

`r2()` computes either the Bayes r-squared value, or - if `loo = TRUE` - a LOO-adjusted r-squared value (which comes conceptionally closer to an adjusted r-squared measure).

For the Bayes r-squared, the standard error is also reported. Note that `r2()` uses the median as measure of central tendency and the median absolute deviation as measure for variability.

```{r}
r2(m5)

r2(m5, loo = TRUE)
```

## References

Kruschke JK. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd edition. Academic Press, 2015 

Kruschke JK. Rejecting or Accepting Parameter Values in Bayesian Estimation. Advances in Methods and Practices in Psychological Science. 2018; doi: [10.1177/2515245918771304 ](https://doi.org/10.1177/2515245918771304)

McElreath R. Statistical Rethinking. A Bayesian Course with Examples in R and Stan. Chapman and Hall, 2015

Norman GR, Sloan JA, Wyrwich KW. Interpretation of Changes in Health-related Quality of Life: The Remarkable Universality of Half a Standard Deviation. Medical Care. 2003;41: 582–592. doi: [10.1097/01.MLR.0000062554.74615.4C](https://doi.org/10.1097/01.MLR.0000062554.74615.4C)
